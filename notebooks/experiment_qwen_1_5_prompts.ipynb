{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "000DhCn0Lyv_",
        "outputId": "0fc70a8a-d333-4259-a789-b385c7d7794a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_project'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 169 (delta 87), reused 138 (delta 57), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (169/169), 45.11 KiB | 733.00 KiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf NLP_project\n",
        "!git clone https://github.com/lucapl/NLP_project.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r NLP_project/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrqvUW9kMZxH",
        "outputId": "2ee9a644-f40e-4445-8554-d62a757aef9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-score (from -r NLP_project/requirements.txt (line 1))\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_score (from -r NLP_project/requirements.txt (line 2))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets (from -r NLP_project/requirements.txt (line 3))\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate (from -r NLP_project/requirements.txt (line 4))\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r NLP_project/requirements.txt (line 5)) (4.41.2)\n",
            "Collecting py7zr (from -r NLP_project/requirements.txt (line 6))\n",
            "  Downloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft (from -r NLP_project/requirements.txt (line 7))\n",
            "  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio (from -r NLP_project/requirements.txt (line 8))\n",
            "  Downloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r NLP_project/requirements.txt (line 9))\n",
            "  Downloading wandb-0.17.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score->-r NLP_project/requirements.txt (line 1)) (2.3.0+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score->-r NLP_project/requirements.txt (line 1)) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score->-r NLP_project/requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score->-r NLP_project/requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score->-r NLP_project/requirements.txt (line 1)) (4.66.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score->-r NLP_project/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score->-r NLP_project/requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score->-r NLP_project/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score->-r NLP_project/requirements.txt (line 2)) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score->-r NLP_project/requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r NLP_project/requirements.txt (line 3)) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r NLP_project/requirements.txt (line 3)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r NLP_project/requirements.txt (line 3)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r NLP_project/requirements.txt (line 3))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->-r NLP_project/requirements.txt (line 3))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r NLP_project/requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r NLP_project/requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r NLP_project/requirements.txt (line 3)) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets->-r NLP_project/requirements.txt (line 3)) (0.23.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r NLP_project/requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r NLP_project/requirements.txt (line 5)) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r NLP_project/requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r NLP_project/requirements.txt (line 5)) (0.4.3)\n",
            "Collecting texttable (from py7zr->-r NLP_project/requirements.txt (line 6))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr->-r NLP_project/requirements.txt (line 6))\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.15.9 (from py7zr->-r NLP_project/requirements.txt (line 6))\n",
            "  Downloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.8/413.8 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->-r NLP_project/requirements.txt (line 6))\n",
            "  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->-r NLP_project/requirements.txt (line 6))\n",
            "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr->-r NLP_project/requirements.txt (line 6))\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->-r NLP_project/requirements.txt (line 6))\n",
            "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli>=1.1.0 (from py7zr->-r NLP_project/requirements.txt (line 6))\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr->-r NLP_project/requirements.txt (line 6)) (5.9.5)\n",
            "Collecting accelerate>=0.21.0 (from peft->-r NLP_project/requirements.txt (line 7))\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r NLP_project/requirements.txt (line 8)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.0.1 (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r NLP_project/requirements.txt (line 8)) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r NLP_project/requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r NLP_project/requirements.txt (line 8)) (2.1.5)\n",
            "Collecting orjson~=3.0 (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading orjson-3.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r NLP_project/requirements.txt (line 8)) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r NLP_project/requirements.txt (line 8)) (2.7.3)\n",
            "Collecting pydub (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r NLP_project/requirements.txt (line 8)) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r NLP_project/requirements.txt (line 8)) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r NLP_project/requirements.txt (line 8)) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r NLP_project/requirements.txt (line 9)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r NLP_project/requirements.txt (line 9))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r NLP_project/requirements.txt (line 9))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r NLP_project/requirements.txt (line 9)) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r NLP_project/requirements.txt (line 9)) (3.20.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r NLP_project/requirements.txt (line 9))\n",
            "  Downloading sentry_sdk-2.5.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r NLP_project/requirements.txt (line 9))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r NLP_project/requirements.txt (line 9)) (67.7.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r NLP_project/requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r NLP_project/requirements.txt (line 8)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r NLP_project/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r NLP_project/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r NLP_project/requirements.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r NLP_project/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r NLP_project/requirements.txt (line 3)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r NLP_project/requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r NLP_project/requirements.txt (line 3)) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r NLP_project/requirements.txt (line 9))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r NLP_project/requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r NLP_project/requirements.txt (line 8)) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r NLP_project/requirements.txt (line 8)) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r NLP_project/requirements.txt (line 8)) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r NLP_project/requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r NLP_project/requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r NLP_project/requirements.txt (line 1)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r NLP_project/requirements.txt (line 1)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r NLP_project/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r NLP_project/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score->-r NLP_project/requirements.txt (line 1)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score->-r NLP_project/requirements.txt (line 1)) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r NLP_project/requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r NLP_project/requirements.txt (line 8)) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score->-r NLP_project/requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1)) (3.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r NLP_project/requirements.txt (line 8)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r NLP_project/requirements.txt (line 8)) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score->-r NLP_project/requirements.txt (line 2)) (1.4.2)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r NLP_project/requirements.txt (line 9))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r NLP_project/requirements.txt (line 8)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r NLP_project/requirements.txt (line 8)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r NLP_project/requirements.txt (line 8)) (0.18.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r NLP_project/requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r NLP_project/requirements.txt (line 8)) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio->-r NLP_project/requirements.txt (line 8)) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio->-r NLP_project/requirements.txt (line 8))\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score->-r NLP_project/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r NLP_project/requirements.txt (line 8)) (0.1.2)\n",
            "Building wheels for collected packages: rouge_score, ffmpy\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=2e3d16bd93179c4ea89424755bcfed23af160f8247323690652b580ce90f3ade\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=30c8e958f04602eb5e5ee27a0e28a6aa477bca161cb5baefc7cc1692f39ce888\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built rouge_score ffmpy\n",
            "Installing collected packages: texttable, pydub, ffmpy, brotli, xxhash, websockets, uvloop, ujson, tomlkit, smmap, setproctitle, sentry-sdk, semantic-version, ruff, requests, pyzstd, python-multipart, python-dotenv, pyppmd, pycryptodomex, pybcj, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multivolumefile, inflate64, httptools, h11, docker-pycreds, dnspython, dill, aiofiles, watchfiles, uvicorn, starlette, rouge_score, py7zr, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, httpcore, gitdb, email_validator, nvidia-cusolver-cu12, httpx, gitpython, wandb, gradio-client, fastapi-cli, datasets, fastapi, evaluate, bert-score, accelerate, peft, gradio\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.31.0 aiofiles-23.2.1 bert-score-0.3.13 brotli-1.1.0 datasets-2.19.2 dill-0.3.8 dnspython-2.6.1 docker-pycreds-0.4.0 email_validator-2.1.1 evaluate-0.4.2 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gitdb-4.0.11 gitpython-3.1.43 gradio-4.36.1 gradio-client-1.0.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 inflate64-1.0.0 multiprocess-0.70.16 multivolumefile-0.2.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 orjson-3.10.4 peft-0.11.1 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pydub-0.25.1 pyppmd-1.1.0 python-dotenv-1.0.1 python-multipart-0.0.9 pyzstd-0.16.0 requests-2.32.3 rouge_score-0.1.2 ruff-0.4.8 semantic-version-2.10.0 sentry-sdk-2.5.1 setproctitle-1.3.3 smmap-5.0.1 starlette-0.37.2 texttable-1.7.0 tomlkit-0.12.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 wandb-0.17.1 watchfiles-0.22.0 websockets-11.0.3 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "RUJ4WlchSaeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 NLP_project/src/experiment_qwen_few_shot.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWRvu85zNHyG",
        "outputId": "35a9b9f8-24af-4df9-83f5-bcda678474c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-12 21:46:26.865548: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-06-12 21:46:26.919300: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-12 21:46:26.919359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-12 21:46:26.921210: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-12 21:46:26.929831: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-12 21:46:28.106098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "config.json: 100% 931/931 [00:00<00:00, 6.51MB/s]\n",
            "model.safetensors.index.json: 100% 16.3k/16.3k [00:00<00:00, 76.3MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.97G [00:00<01:14, 66.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.97G [00:00<01:11, 69.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.97G [00:00<01:02, 79.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.97G [00:00<00:56, 87.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/4.97G [00:00<00:46, 105MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.97G [00:00<00:41, 118MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.97G [00:00<00:39, 123MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/4.97G [00:01<00:37, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.97G [00:01<00:36, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.97G [00:01<00:35, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.97G [00:01<00:35, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.97G [00:01<00:34, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.97G [00:01<00:34, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.97G [00:02<00:33, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.97G [00:02<00:33, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.97G [00:02<00:33, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.97G [00:02<00:33, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.97G [00:02<00:33, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.97G [00:02<00:32, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.97G [00:02<00:33, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.97G [00:03<00:32, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.97G [00:03<00:34, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.97G [00:03<00:33, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.97G [00:03<00:33, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.97G [00:03<00:32, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/4.97G [00:03<00:32, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.97G [00:04<00:32, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/4.97G [00:04<00:31, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/4.97G [00:04<00:31, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.97G [00:04<00:31, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.97G [00:04<00:31, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.97G [00:04<00:31, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.97G [00:04<00:30, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 671M/4.97G [00:05<00:30, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.97G [00:05<00:30, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/4.97G [00:05<00:30, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.97G [00:05<00:30, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.97G [00:05<00:30, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.97G [00:05<00:30, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.97G [00:05<00:30, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.97G [00:06<00:29, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/4.97G [00:06<00:29, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.97G [00:06<00:29, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.97G [00:06<00:29, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.97G [00:06<00:29, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 923M/4.97G [00:06<00:29, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/4.97G [00:07<00:28, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.97G [00:07<00:28, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.97G [00:07<00:28, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.97G [00:07<00:28, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.97G [00:07<00:28, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.97G [00:07<00:27, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.97G [00:07<00:27, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.97G [00:08<00:27, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.97G [00:08<00:27, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.97G [00:08<00:27, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/4.97G [00:08<00:27, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.97G [00:08<00:27, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/4.97G [00:08<00:27, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.97G [00:08<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.97G [00:09<00:26, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/4.97G [00:09<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.97G [00:09<00:26, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.97G [00:09<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.32G/4.97G [00:09<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.97G [00:09<00:25, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.97G [00:10<00:25, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.97G [00:10<00:32, 109MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.97G [00:10<00:33, 105MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.97G [00:10<00:36, 97.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.97G [00:10<00:39, 89.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.97G [00:11<00:42, 82.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.97G [00:11<00:43, 81.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.47G/4.97G [00:11<00:49, 71.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.97G [00:11<00:45, 75.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.97G [00:11<00:48, 72.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.97G [00:11<00:46, 73.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.97G [00:12<00:45, 76.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.97G [00:12<00:44, 78.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.97G [00:12<00:42, 81.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.97G [00:12<00:43, 78.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/4.97G [00:12<00:41, 82.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.57G/4.97G [00:12<00:44, 76.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.97G [00:12<00:41, 80.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.97G [00:13<00:43, 78.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.97G [00:13<00:42, 79.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.61G/4.97G [00:13<00:44, 75.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.97G [00:13<00:40, 82.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.97G [00:13<00:40, 82.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/4.97G [00:13<00:42, 78.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.97G [00:14<00:45, 72.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.97G [00:14<00:46, 71.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.97G [00:14<00:48, 67.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.97G [00:14<00:37, 86.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.97G [00:14<00:31, 102MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.97G [00:14<00:28, 113MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.97G [00:14<00:26, 120MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.97G [00:15<00:25, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.81G/4.97G [00:15<00:24, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.97G [00:15<00:23, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.97G [00:15<00:23, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.97G [00:15<00:22, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.97G [00:15<00:22, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.97G [00:15<00:22, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.97G [00:16<00:21, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.97G [00:16<00:21, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.97G [00:16<00:21, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.97G [00:16<00:21, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.97G [00:16<00:20, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.97G [00:16<00:21, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.97G [00:17<00:20, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.97G [00:17<00:20, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/4.97G [00:17<00:20, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.97G [00:17<00:20, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.97G [00:17<00:20, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.97G [00:17<00:20, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.97G [00:17<00:19, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.21G/4.97G [00:18<00:19, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.97G [00:18<00:19, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.97G [00:18<00:19, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.97G [00:18<00:19, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.97G [00:18<00:19, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.97G [00:18<00:18, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.97G [00:18<00:18, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.36G/4.97G [00:19<00:18, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.97G [00:19<00:18, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.97G [00:19<00:18, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.97G [00:19<00:18, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.97G [00:19<00:18, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.46G/4.97G [00:19<00:18, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.97G [00:20<00:17, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.97G [00:20<00:17, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.97G [00:20<00:17, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/4.97G [00:20<00:17, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.97G [00:20<00:17, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.97G [00:20<00:16, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.97G [00:20<00:16, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.97G [00:21<00:16, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.97G [00:21<00:16, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.97G [00:21<00:16, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/4.97G [00:21<00:16, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.72G/4.97G [00:21<00:16, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.97G [00:21<00:15, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.76G/4.97G [00:21<00:15, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.97G [00:22<00:15, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.97G [00:22<00:15, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.97G [00:22<00:15, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/4.97G [00:22<00:15, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.86G/4.97G [00:22<00:15, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.97G [00:22<00:14, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/4.97G [00:23<00:14, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.97G [00:23<00:14, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.97G [00:23<00:14, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.97G [00:23<00:14, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.97G [00:23<00:14, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.01G/4.97G [00:23<00:13, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.97G [00:23<00:13, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.97G [00:24<00:13, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.97G [00:24<00:13, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/4.97G [00:24<00:13, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.11G/4.97G [00:24<00:16, 114MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.97G [00:24<00:18, 97.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.16G/4.97G [00:25<00:22, 80.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.97G [00:25<00:22, 81.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.97G [00:25<00:22, 80.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/4.97G [00:25<00:20, 86.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.21G/4.97G [00:26<00:24, 70.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.97G [00:26<00:24, 71.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.97G [00:26<00:24, 72.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/4.97G [00:26<00:19, 89.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.26G/4.97G [00:26<00:24, 70.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.97G [00:26<00:19, 86.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.97G [00:27<00:19, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.30G/4.97G [00:27<00:20, 81.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.31G/4.97G [00:27<00:22, 75.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.97G [00:27<00:23, 69.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.97G [00:27<00:27, 59.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.97G [00:27<00:24, 67.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.37G/4.97G [00:28<00:18, 87.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/4.97G [00:28<00:16, 98.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.97G [00:28<00:14, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.97G [00:28<00:12, 119MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.97G [00:28<00:17, 89.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.97G [00:29<00:15, 97.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.97G [00:29<00:13, 106MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.51G/4.97G [00:29<00:12, 115MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.97G [00:29<00:11, 121MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.55G/4.97G [00:29<00:11, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.97G [00:29<00:10, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.97G [00:29<00:10, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.97G [00:30<00:10, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/4.97G [00:30<00:09, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.66G/4.97G [00:30<00:09, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.97G [00:30<00:09, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.70G/4.97G [00:30<00:09, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.97G [00:30<00:08, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.97G [00:30<00:08, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.76G/4.97G [00:31<00:08, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.97G [00:31<00:08, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.97G [00:31<00:08, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.97G [00:31<00:08, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.97G [00:31<00:07, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.97G [00:31<00:07, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/4.97G [00:31<00:07, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.97G [00:32<00:07, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.97G [00:32<00:07, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.95G/4.97G [00:32<00:07, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.97G [00:32<00:07, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/4.97G [00:32<00:06, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.97G [00:32<00:06, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.97G [00:33<00:06, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.06G/4.97G [00:33<00:06, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.97G [00:33<00:06, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.10G/4.97G [00:33<00:06, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.97G [00:33<00:06, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.97G [00:33<00:05, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.16G/4.97G [00:33<00:05, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.97G [00:34<00:05, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.20G/4.97G [00:34<00:05, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.97G [00:34<00:05, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/4.97G [00:34<00:05, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.97G [00:34<00:04, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.97G [00:34<00:04, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.97G [00:34<00:04, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.97G [00:35<00:04, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.97G [00:35<00:04, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.97G [00:35<00:04, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.39G/4.97G [00:35<00:04, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.97G [00:35<00:04, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.97G [00:35<00:03, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.46G/4.97G [00:36<00:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.97G [00:36<00:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.50G/4.97G [00:36<00:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.97G [00:36<00:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.97G [00:36<00:03, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.97G [00:36<00:02, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.97G [00:36<00:02, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.97G [00:37<00:02, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.97G [00:37<00:02, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.65G/4.97G [00:37<00:02, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.97G [00:37<00:02, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.97G [00:37<00:02, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.71G/4.97G [00:37<00:01, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.97G [00:38<00:01, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.75G/4.97G [00:38<00:01, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.97G [00:38<00:01, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/4.97G [00:38<00:01, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.97G [00:38<00:01, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/4.97G [00:38<00:00, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.97G [00:38<00:00, 119MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.97G [00:39<00:00, 98.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.90G/4.97G [00:39<00:00, 80.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.91G/4.97G [00:39<00:00, 81.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.92G/4.97G [00:39<00:00, 72.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/4.97G [00:40<00:00, 62.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.97G [00:40<00:00, 59.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.95G/4.97G [00:40<00:00, 57.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.97G [00:40<00:00, 61.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [00:41<00:00, 121MB/s] \n",
            "Downloading shards:  50% 1/2 [00:41<00:41, 41.22s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.67G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 10.5M/2.67G [00:00<00:40, 65.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/2.67G [00:00<00:33, 79.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/2.67G [00:00<00:30, 87.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 41.9M/2.67G [00:00<00:28, 90.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 52.4M/2.67G [00:00<00:29, 90.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 73.4M/2.67G [00:00<00:21, 121MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 94.4M/2.67G [00:00<00:19, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 115M/2.67G [00:01<00:19, 133MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 136M/2.67G [00:01<00:18, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 157M/2.67G [00:01<00:18, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 178M/2.67G [00:01<00:18, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 199M/2.67G [00:01<00:18, 134MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 220M/2.67G [00:01<00:18, 136MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 241M/2.67G [00:01<00:17, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 262M/2.67G [00:02<00:17, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 283M/2.67G [00:02<00:17, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 304M/2.67G [00:02<00:17, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 325M/2.67G [00:02<00:16, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 346M/2.67G [00:02<00:16, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 367M/2.67G [00:02<00:16, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 388M/2.67G [00:02<00:16, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 409M/2.67G [00:03<00:16, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 430M/2.67G [00:03<00:16, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 451M/2.67G [00:03<00:16, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 472M/2.67G [00:03<00:15, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 493M/2.67G [00:03<00:15, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 514M/2.67G [00:03<00:15, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 535M/2.67G [00:04<00:15, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 556M/2.67G [00:04<00:15, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 577M/2.67G [00:04<00:15, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 598M/2.67G [00:04<00:14, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 619M/2.67G [00:04<00:14, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 640M/2.67G [00:04<00:14, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 661M/2.67G [00:04<00:14, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 682M/2.67G [00:05<00:14, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 703M/2.67G [00:05<00:14, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 724M/2.67G [00:05<00:14, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 744M/2.67G [00:05<00:13, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 765M/2.67G [00:05<00:13, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 786M/2.67G [00:05<00:13, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 807M/2.67G [00:06<00:13, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 828M/2.67G [00:06<00:13, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 849M/2.67G [00:06<00:13, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 870M/2.67G [00:06<00:12, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 891M/2.67G [00:06<00:12, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 912M/2.67G [00:06<00:12, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 933M/2.67G [00:06<00:12, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 954M/2.67G [00:07<00:12, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 975M/2.67G [00:07<00:12, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 996M/2.67G [00:07<00:12, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.02G/2.67G [00:07<00:11, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.04G/2.67G [00:07<00:11, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.06G/2.67G [00:07<00:11, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.08G/2.67G [00:07<00:11, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.10G/2.67G [00:08<00:11, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.12G/2.67G [00:08<00:11, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.14G/2.67G [00:08<00:10, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.16G/2.67G [00:08<00:11, 132MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.18G/2.67G [00:08<00:10, 136MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.21G/2.67G [00:08<00:10, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.23G/2.67G [00:09<00:10, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.25G/2.67G [00:09<00:10, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.27G/2.67G [00:09<00:10, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.29G/2.67G [00:09<00:10, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.31G/2.67G [00:09<00:09, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.33G/2.67G [00:09<00:09, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.35G/2.67G [00:09<00:09, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.37G/2.67G [00:10<00:09, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.39G/2.67G [00:10<00:11, 110MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.42G/2.67G [00:10<00:13, 92.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.43G/2.67G [00:10<00:15, 78.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.44G/2.67G [00:11<00:15, 78.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.45G/2.67G [00:11<00:16, 75.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.46G/2.67G [00:11<00:16, 74.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.47G/2.67G [00:11<00:18, 64.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.48G/2.67G [00:11<00:18, 65.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.49G/2.67G [00:12<00:20, 58.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.51G/2.67G [00:12<00:16, 71.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.52G/2.67G [00:12<00:16, 69.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.53G/2.67G [00:12<00:17, 65.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 1.54G/2.67G [00:12<00:17, 64.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 1.55G/2.67G [00:12<00:17, 63.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 1.56G/2.67G [00:13<00:17, 64.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 1.57G/2.67G [00:13<00:17, 63.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 1.58G/2.67G [00:13<00:17, 63.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 1.59G/2.67G [00:13<00:16, 66.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 1.60G/2.67G [00:13<00:15, 67.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 1.61G/2.67G [00:13<00:15, 66.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 1.63G/2.67G [00:14<00:16, 64.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 1.65G/2.67G [00:14<00:11, 86.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 1.67G/2.67G [00:14<00:09, 101MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 1.69G/2.67G [00:14<00:08, 111MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 1.71G/2.67G [00:14<00:08, 120MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 1.73G/2.67G [00:14<00:07, 125MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 1.75G/2.67G [00:14<00:07, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 1.77G/2.67G [00:15<00:06, 131MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 1.79G/2.67G [00:15<00:06, 134MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 1.81G/2.67G [00:15<00:06, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 1.84G/2.67G [00:15<00:06, 136MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.86G/2.67G [00:15<00:05, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.88G/2.67G [00:15<00:05, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 1.90G/2.67G [00:15<00:05, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 1.92G/2.67G [00:16<00:05, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 1.94G/2.67G [00:16<00:05, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 1.96G/2.67G [00:16<00:05, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 1.98G/2.67G [00:16<00:04, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.00G/2.67G [00:16<00:04, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.02G/2.67G [00:16<00:04, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.04G/2.67G [00:17<00:04, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.07G/2.67G [00:17<00:04, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.09G/2.67G [00:17<00:04, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.11G/2.67G [00:17<00:04, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.13G/2.67G [00:17<00:03, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.15G/2.67G [00:17<00:03, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.17G/2.67G [00:17<00:03, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.19G/2.67G [00:18<00:03, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.21G/2.67G [00:18<00:03, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.23G/2.67G [00:18<00:03, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.25G/2.67G [00:18<00:02, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.28G/2.67G [00:18<00:02, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 2.30G/2.67G [00:18<00:02, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 2.32G/2.67G [00:19<00:02, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 2.34G/2.67G [00:19<00:02, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 2.36G/2.67G [00:19<00:02, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 2.38G/2.67G [00:19<00:02, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 2.40G/2.67G [00:19<00:01, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 2.42G/2.67G [00:19<00:01, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 2.44G/2.67G [00:19<00:01, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 2.46G/2.67G [00:20<00:01, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 2.49G/2.67G [00:20<00:01, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 2.51G/2.67G [00:20<00:01, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 2.53G/2.67G [00:20<00:01, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 2.55G/2.67G [00:20<00:00, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 2.57G/2.67G [00:20<00:00, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 2.59G/2.67G [00:20<00:00, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 2.61G/2.67G [00:21<00:00, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 2.63G/2.67G [00:21<00:00, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 2.65G/2.67G [00:21<00:00, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 2.67G/2.67G [00:21<00:00, 124MB/s]\n",
            "Downloading shards: 100% 2/2 [01:02<00:00, 31.47s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.15s/it]\n",
            "generation_config.json: 100% 172/172 [00:00<00:00, 1.32MB/s]\n",
            "tokenizer_config.json: 100% 3.17k/3.17k [00:00<00:00, 17.2MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 307MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 9.12MB/s]\n",
            "added_tokens.json: 100% 293/293 [00:00<00:00, 1.87MB/s]\n",
            "special_tokens_map.json: 100% 568/568 [00:00<00:00, 4.14MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkorba-adam\u001b[0m (\u001b[33mput-cv\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240612_214745-l4bsovoy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmicrosoft/Phi-3-mini-4k-instruct0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization/runs/l4bsovoy\u001b[0m\n",
            "Summarizing 100 docs\n",
            "You are not running the flash-attention implementation, expect numerical differences.\n",
            "Finished summarizing in 493.57 seconds\n",
            "Evaluating predictions using BERTscore (microsoft/deberta-v3-small)\n",
            "Evaluated using BERTscore in 1.53 seconds\n",
            "Evalyuating predictions using rouge\n",
            "Evaluated in 0.12 seconds\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        mean_f1 0.7532\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: mean_precision 0.70385\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    mean_recall 0.81165\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    mean_rouge1 0.34243\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    mean_rouge2 0.10962\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    mean_rougeL 0.25603\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: mean_rougeLsum 0.25655\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmicrosoft/Phi-3-mini-4k-instruct0\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization/runs/l4bsovoy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240612_214745-l4bsovoy/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240612_215608-hy4gvy4m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmicrosoft/Phi-3-mini-4k-instruct1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization/runs/hy4gvy4m\u001b[0m\n",
            "Summarizing 100 docs\n",
            "Finished summarizing in 492.72 seconds\n",
            "Evaluating predictions using BERTscore (microsoft/deberta-v3-small)\n",
            "Evaluated using BERTscore in 1.40 seconds\n",
            "Evalyuating predictions using rouge\n",
            "Evaluated in 0.13 seconds\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        mean_f1 0.7532\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: mean_precision 0.70385\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    mean_recall 0.81165\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    mean_rouge1 0.34243\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    mean_rouge2 0.10962\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    mean_rougeL 0.25603\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: mean_rougeLsum 0.25655\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmicrosoft/Phi-3-mini-4k-instruct1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization/runs/hy4gvy4m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240612_215608-hy4gvy4m/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240612_220429-381i2w8z\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmicrosoft/Phi-3-mini-4k-instruct2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization/runs/381i2w8z\u001b[0m\n",
            "Summarizing 100 docs\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NLP_project/src/experiment_qwen_few_shot.py\", line 41, in <module>\n",
            "    results, metrics = evaluate_summarizer(testset, summarizer)\n",
            "  File \"/content/NLP_project/src/evaluator.py\", line 61, in evaluate_summarizer\n",
            "    predictions = generate_summaries(dialogues, summarizer)\n",
            "  File \"/content/NLP_project/src/evaluator.py\", line 82, in generate_summaries\n",
            "    summaries = summarizer(dialogues)\n",
            "  File \"/content/NLP_project/src/summarizer.py\", line 17, in __call__\n",
            "    return self.summarize(prompts)\n",
            "  File \"/content/NLP_project/src/summarizer.py\", line 54, in summarize\n",
            "    predictions = self.pipe(prompts)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\", line 263, in __call__\n",
            "    return super().__call__(text_inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 1224, in __call__\n",
            "    outputs = list(final_iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
            "    item = next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\", line 125, in __next__\n",
            "    processed = self.infer(item, **self.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 1150, in forward\n",
            "    model_outputs = self._forward(model_inputs, **forward_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\", line 350, in _forward\n",
            "    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 1758, in generate\n",
            "    result = self._sample(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 2392, in _sample\n",
            "    while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 1922, in _has_unfinished_sequences\n",
            "    elif this_peer_finished:\n",
            "KeyboardInterrupt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmicrosoft/Phi-3-mini-4k-instruct2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization/runs/381i2w8z\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/put-cv/NLP_summarization\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240612_220429-381i2w8z/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I stopped the experiment earlier after not seeing good results, the idea is to maybe change a little format in wchich instructions are being given because right now I am not following phi3 manual"
      ],
      "metadata": {
        "id": "_A8xst-QQNVZ"
      }
    }
  ]
}